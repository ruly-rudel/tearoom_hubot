# Description:
#   RSS Reformatter for Dropbox
#   Custormized for EX NOTES
#
# Author:
#   @kaminogi
#
# Thanks to
#   @shokai

'use strict'



events     = require 'events'
_          = require 'lodash'
request    = require 'request'
FeedParser = require 'feedparser'
Entities   = require('html-entities').XmlEntities
entities   = new Entities
async      = require 'async'
debug      = require('debug')('hubot-rss-reader:rss-checker')
cheerio    = require 'cheerio'
Promise    = require 'bluebird'

## original rss checker
OriginalRSSChecker = require '../../libs/rss-checker'



dropbox_username   = process.env.HUBOT_RSS_DROPBOX_USERNAME || "kaminogi"
dropbox_dir_name   = process.env.HUBOT_RSS_DROPBOX_DIRNAME || "EX NOTES"

class RSSChecker extends OriginalRSSChecker

  cleanup_summary = (html) ->
    summary = do (html) ->
      try
        $ = cheerio.load html
        if img = $('img').attr('src')
          return img + '\n' + $.root().text()
        return $.root().text()
      catch
        return html
    lines = summary.split /[\r\n]/
    lines = lines.map (line) -> if /^\s+$/.test line then '' else line
    summary = lines.join '\n'
    return summary.replace(/\n\n\n+/g, '\n\n')

  cleanup_dropbox_item = (html = '') ->
    $ = cheerio.load html
    if $("a[href^='/event_details']").attr("href")
        event_url = $("a[href^='/event_details']").attr("href")

    item_text = do (html) ->
      try
        $ = cheerio.load html
        if img = $('img').attr('src')
          return img + '\n' + $.root().text()
        return $.root().text()
      catch
        return html
    lines = item_text.split /[\r\n]/
    lines = lines.map (line) -> if /^\s+$/.test line then '' else line
    item_text = lines.join '\n'

    if /\._.+?\.$/.test(item_text)
      return false

    # add specific rules here.
    item_text = item_text.replace /you/i, dropbox_username
    item_text = item_text.replace "In #{dropbox_dir_name}, ", ""
    item_text = item_text.replace "the file ", ""
    item_text = item_text.replace /and ([0-9]+) more files/, "（他$1ファイル）"

    action = ""

    switch true
      when /edited/.test(item_text)
        action = "編集"
      when /deleted/.test(item_text)
        action = "削除"
      when /added/.test(item_text)
        action = "作成"
      when /moved/.test(item_text)
        action = "移動"
      when /renamed/.test(item_text)
        action = "名前変更"

    item_text = item_text.replace /edited|deleted|added|moved|renamed/, "が"
    item_text = item_text.replace /\.$/, ""

    item_text += " を" + action + "したみたい。"

    title   = item_text
    summary = ""

    if event_url != undefined
        summary += "詳しくは "
        summary += "https://dropbox.com"
        summary += event_url
        summary += " のログを見て。"


    #console.log "title: ", title
    #console.log "summary:", summary

    return [title,summary,event_url]

  check: (opts = {init: no}) ->
    new Promise (resolve) =>
      debug "start checking all feeds"
      feeds = []
      for room, _feeds of (opts.feeds or @robot.brain.get('feeds'))
        feeds = feeds.concat _feeds
      resolve _.uniq feeds
    .then (feeds) =>
      interval = 1
      Promise.each feeds, (url) =>
        console.log("feed url", url)
        new Promise (resolve) ->
          setTimeout =>
            resolve url
          , interval
          interval = 5000
        .then (url) =>
          do (opts) =>
            opts.url = url
            console.log("start fetching", opts)
            @fetch opts
        .then =>
          @emit 'checked the site'

        .catch (err) =>
          debug err
          @emit 'error', {error: err, feed: {url: url}}
    .then (feeds) ->
      new Promise (resolve) ->
        debug "check done (#{feeds?.length or 0} feeds)"

        resolve feeds

  fetch: (args) ->
    new Promise (resolve, reject) =>
      default_args =
        url: null
        init: no
        room: null

      if typeof args is 'string'
        args = {url: args}
      for k,v of default_args
        unless args.hasOwnProperty k
          args[k] = v
      debug "fetch #{args.url}"
      debug args
      feedparser = new FeedParser
      req = request
        uri: args.url
        timeout: 10000
        headers:
          'User-Agent': process.env.HUBOT_RSS_USERAGENT
          'Accept-Language': "en"

      req.on 'error', (err) ->
        reject err

      req.on 'response', (res) ->
        stream = this
        if res.statusCode isnt 200
          return reject "statusCode: #{res.statusCode}"
        stream.pipe feedparser

      feedparser.on 'error', (err) ->
        reject err

      entries = []

      feedparser.on 'data', (chunk) =>
        dropbox = chunk.link.match /dropbox\.com/
        calendar = chunk.link.match /www.google.com\/calendar/
        internal = chunk.link.match /internal.hogehoge.com/

        if dropbox
            process.env.HUBOT_RSS_HEADER = ":dropbox:"
            [title, summary,event_url] = cleanup_dropbox_item entities.decode(chunk.summary or chunk.description or '')
            chunk.link = event_url
            if !title
              return
        else
            summary = cleanup_summary entities.decode(chunk.summary or chunk.description or '')
            title = entities.decode(chunk.title or '')

        debug summary, title
        entry =
          url: chunk.link
          title: title
          summary: summary
          feed:
            url: args.url
            title: "Dropbox"
          toString: ->
            s = ""
            if dropbox
              s += "#{process.env.HUBOT_RSS_HEADER} #{@title} \n"
            else if calendar
              s = ":date: ﾍｰｰｰｲ提督ゥwwwww New event has been created!\n"
              s += "*#{@title}* \n"
            else if internal
              s = ":ex-notes: 新しい情報がアップロードされたネー！\n"
              s += "*#{@title}* \n"
            else
              s = ":star2: New RSS が登場ｼﾀﾖｰｰｰｰｰwwwwwwww\n"
              s += "*#{@title}* \n"

            s += @url + "\n" unless dropbox
            s += "\n#{@summary}" if @summary?.length > 0
            return s
          args: args

        debug entry
        entries.push entry

        unless @cache[entry.url]
          @cache[entry.url] = true
          return if args.init
          @emit 'new entry', entry

      feedparser.on 'end', ->
        resolve entries


module.exports = RSSChecker
